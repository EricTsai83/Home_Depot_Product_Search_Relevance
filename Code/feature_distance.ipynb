{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "entire-completion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@author: Eric Tsai <eric492718@gmail.com>\\n@brief: distance features\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: Eric Tsai <eric492718@gmail.com>\n",
    "@brief: distance features\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "absent-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "from utils import dist_utils, ngram_utils, nlp_utils\n",
    "from utils import logging_utils, time_utils, pkl_utils\n",
    "from feature_base import BaseEstimator, PairwiseFeatureWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "broadband-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune the token pattern to get a better correlation with y_train\n",
    "# token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "# token_pattern = r\"\\w{1,}\"\n",
    "# token_pattern = r\"\\w+\"\n",
    "# token_pattern = r\"[\\w']+\"\n",
    "token_pattern = \" \" # just split the text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adjusted-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- Jaccard & Dice --------------------------------------\n",
    "class JaccardCoef_Ngram(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Intersection over Union\n",
    "    \"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, aggregation_mode)\n",
    "        self.ngram = ngram\n",
    "        self.ngram_str = ngram_utils._ngram_str_map[self.ngram]\n",
    "\n",
    "    def __name__(self):\n",
    "        return \"JaccardCoef_%s\"%self.ngram_str\n",
    "\n",
    "    def transform_one(self, obs, target, id):\n",
    "        obs_tokens = nlp_utils._tokenize(obs, token_pattern)\n",
    "        target_tokens = nlp_utils._tokenize(target, token_pattern)\n",
    "        obs_ngrams = ngram_utils._ngrams(obs_tokens, self.ngram)\n",
    "        target_ngrams = ngram_utils._ngrams(target_tokens, self.ngram)\n",
    "        return dist_utils._jaccard_coef(obs_ngrams, target_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "objective-shock",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceDistance_Ngram(BaseEstimator):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, aggregation_mode)\n",
    "        self.ngram = ngram\n",
    "        self.ngram_str = ngram_utils._ngram_str_map[self.ngram]\n",
    "\n",
    "    def __name__(self):\n",
    "        return \"DiceDistance_%s\"%self.ngram_str\n",
    "\n",
    "    def transform_one(self, obs, target, id):\n",
    "        obs_tokens = nlp_utils._tokenize(obs, token_pattern)\n",
    "        target_tokens = nlp_utils._tokenize(target, token_pattern)\n",
    "        obs_ngrams = ngram_utils._ngrams(obs_tokens, self.ngram)\n",
    "        target_ngrams = ngram_utils._ngrams(target_tokens, self.ngram)\n",
    "        return dist_utils._dice_dist(obs_ngrams, target_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "separated-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Edit Distance --------------------------------\n",
    "class EditDistance(BaseEstimator):\n",
    "    def __init__(self, obs_corpus, target_corpus, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, aggregation_mode)\n",
    "    \n",
    "    def __name__(self):\n",
    "        return \"EditDistance\"\n",
    "\n",
    "    def transform_one(self, obs, target, id):\n",
    "        return dist_utils._edit_dist(obs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "homeless-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EditDistance_Ngram(BaseEstimator):\n",
    "    \"\"\"Double aggregation features\"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode_prev=\"\", aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, aggregation_mode, None, aggregation_mode_prev)\n",
    "        self.ngram = ngram\n",
    "        self.ngram_str = ngram_utils._ngram_str_map[self.ngram]\n",
    "\n",
    "    def __name__(self):\n",
    "        feat_name = []\n",
    "        for m1 in self.aggregation_mode_prev:\n",
    "            for m in self.aggregation_mode:\n",
    "                n = \"EditDistance_%s_%s_%s\"%(self.ngram_str, string.capwords(m1), string.capwords(m))\n",
    "                feat_name.append(n)\n",
    "        return feat_name\n",
    "\n",
    "    def transform_one(self, obs, target, id):\n",
    "        obs_tokens = nlp_utils._tokenize(obs, token_pattern)\n",
    "        target_tokens = nlp_utils._tokenize(target, token_pattern)\n",
    "        obs_ngrams = ngram_utils._ngrams(obs_tokens, self.ngram)\n",
    "        target_ngrams = ngram_utils._ngrams(target_tokens, self.ngram)\n",
    "        val_list = []\n",
    "        for w1 in obs_ngrams:\n",
    "            _val_list = []\n",
    "            for w2 in target_ngrams:\n",
    "                s = dist_utils._edit_dist(w1, w2)\n",
    "                _val_list.append(s)\n",
    "            if len(_val_list) == 0:\n",
    "                _val_list = [ config.MISSING_VALUE_NUMERIC ]\n",
    "            val_list.append( _val_list )\n",
    "        if len(val_list) == 0:\n",
    "            val_list = [ [config.MISSING_VALUE_NUMERIC] ]\n",
    "        return val_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "clear-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ Compression Distance --------------------------------\n",
    "class CompressionDistance(BaseEstimator):\n",
    "    \"\"\"Very time consuming\"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, aggregation_mode)\n",
    "\n",
    "    def __name__(self):\n",
    "        return \"CompressionDistance\"\n",
    "\n",
    "    def transform_one(self, obs, target, id):\n",
    "        return dist_utils._compression_dist(obs, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "synthetic-ceiling",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CompressionDistance_Ngram(BaseEstimator):\n",
    "    \"\"\"Double aggregation features\"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode_prev=\"\", aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, aggregation_mode, None, aggregation_mode_prev)\n",
    "        self.ngram = ngram\n",
    "        self.ngram_str = ngram_utils._ngram_str_map[self.ngram]\n",
    "\n",
    "    def __name__(self):\n",
    "        feat_name = []\n",
    "        for m1 in self.aggregation_mode_prev:\n",
    "            for m in self.aggregation_mode:\n",
    "                n = \"CompressionDistance_%s_%s_%s\"%(self.ngram_str, string.capwords(m1), string.capwords(m))\n",
    "                feat_name.append(n)\n",
    "        return feat_name\n",
    "\n",
    "    def transform_one(self, obs, target, id):\n",
    "        obs_tokens = nlp_utils._tokenize(obs, token_pattern)\n",
    "        target_tokens = nlp_utils._tokenize(target, token_pattern)\n",
    "        obs_ngrams = ngram_utils._ngrams(obs_tokens, self.ngram)\n",
    "        target_ngrams = ngram_utils._ngrams(target_tokens, self.ngram)\n",
    "        val_list = []\n",
    "        for w1 in obs_ngrams:\n",
    "            _val_list = []\n",
    "            for w2 in target_ngrams:\n",
    "                s = dist_utils._compression_dist(w1, w2)\n",
    "                _val_list.append(s)\n",
    "            if len(_val_list) == 0:\n",
    "                _val_list = [ config.MISSING_VALUE_NUMERIC ]\n",
    "            val_list.append( _val_list )\n",
    "        if len(val_list) == 0:\n",
    "            val_list = [ [config.MISSING_VALUE_NUMERIC] ]\n",
    "        return val_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "iraqi-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Main --------------------------------------\n",
    "def run_ngram_jaccard():\n",
    "    logname = \"generate_feature_ngram_jaccard_%s.log\"%time_utils._timestamp()\n",
    "    logger = logging_utils._get_logger(config.LOG_DIR, logname)\n",
    "    dfAll = pkl_utils._load(config.ALL_DATA_LEMMATIZED_STEMMED)\n",
    "\n",
    "    generators = [JaccardCoef_Ngram, DiceDistance_Ngram]\n",
    "    obs_fields_list = []\n",
    "    target_fields_list = []\n",
    "    obs_fields_list.append( [\"search_term\", \"search_term_product_name\", \"search_term_alt\", \"search_term_auto_corrected\"][:2] )\n",
    "    target_fields_list.append( [\"product_title\", \"product_title_product_name\", \"product_description\", \"product_attribute\", \"product_brand\", \"product_color\"] )\n",
    "    ngrams = [1,2,3,12,123][:3]\n",
    "    for obs_fields, target_fields in zip(obs_fields_list, target_fields_list):\n",
    "        for generator in generators:\n",
    "            for ngram in ngrams:\n",
    "                param_list = [ngram]\n",
    "                pf = PairwiseFeatureWrapper(generator, dfAll, obs_fields, target_fields, param_list, config.FEAT_DIR, logger)\n",
    "                pf.go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "improved-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_edit_distance():\n",
    "    logname = \"generate_feature_edit_distance_%s.log\"%time_utils._timestamp()\n",
    "    logger = logging_utils._get_logger(config.LOG_DIR, logname)\n",
    "    dfAll = pkl_utils._load(config.ALL_DATA_LEMMATIZED_STEMMED)\n",
    "\n",
    "    obs_fields_list = []\n",
    "    target_fields_list = []\n",
    "    obs_fields_list.append( [\"search_term\", \"search_term_product_name\", \"search_term_alt\", \"search_term_auto_corrected\"][:2] )\n",
    "    target_fields_list.append( [\"product_title\", \"product_title_product_name\", \"product_description\", \"product_attribute\", \"product_brand\", \"product_color\"] )\n",
    "    ngrams = [1,2,3,12,123][:3]\n",
    "    aggregation_mode_prev = [\"mean\", \"max\", \"min\", \"median\"]\n",
    "    aggregation_mode = [\"mean\", \"std\", \"max\", \"min\", \"median\"]\n",
    "    for obs_fields, target_fields in zip(obs_fields_list, target_fields_list):\n",
    "        param_list = []\n",
    "        pf = PairwiseFeatureWrapper(EditDistance, dfAll, obs_fields, target_fields, param_list, config.FEAT_DIR, logger)\n",
    "        pf.go()\n",
    "        for ngram in ngrams:\n",
    "            param_list = [ngram, aggregation_mode_prev, aggregation_mode]\n",
    "            pf = PairwiseFeatureWrapper(EditDistance_Ngram, dfAll, obs_fields, target_fields, param_list, config.FEAT_DIR, logger)\n",
    "            pf.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "spiritual-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_compression_distance():\n",
    "    logname = \"generate_feature_compression_distance_%s.log\"%time_utils._timestamp()\n",
    "    logger = logging_utils._get_logger(config.LOG_DIR, logname)\n",
    "    dfAll = pkl_utils._load(config.ALL_DATA_LEMMATIZED_STEMMED)\n",
    "\n",
    "    obs_fields_list = []\n",
    "    target_fields_list = []\n",
    "    obs_fields_list.append( [\"search_term\", \"search_term_product_name\", \"search_term_alt\", \"search_term_auto_corrected\"][:2] )\n",
    "    target_fields_list.append( [\"product_title\", \"product_title_product_name\", \"product_description\", \"product_attribute\", \"product_brand\", \"product_color\"] )\n",
    "    for obs_fields, target_fields in zip(obs_fields_list, target_fields_list):\n",
    "        param_list = []\n",
    "        pf = PairwiseFeatureWrapper(CompressionDistance, dfAll, obs_fields, target_fields, param_list, config.FEAT_DIR, logger)\n",
    "        pf.go()\n",
    "        for ngram in ngrams:\n",
    "            param_list = [ngram, aggregation_mode_prev, aggregation_mode]\n",
    "            pf = PairwiseFeatureWrapper(CompressionDistance_Ngram, dfAll, obs_fields, target_fields, param_list, config.FEAT_DIR, logger)\n",
    "            pf.go()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eight-paradise",
   "metadata": {},
   "source": [
    "**Set the parameter in the main function by using `sys.argv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "royal-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(which):\n",
    "    if which == \"jaccard\":\n",
    "        run_ngram_jaccard()\n",
    "    elif which == \"edit\":\n",
    "        run_edit_distance()\n",
    "    elif which == \"compression\":\n",
    "        run_compression_distance()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "heavy-ordinary",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "included-search",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading feature_distance.ipynb in format ipynb\n",
      "[jupytext] Writing feature_distance.py (destination file replaced)\n"
     ]
    }
   ],
   "source": [
    "# convert notebook.ipynb to a .py file\n",
    "!jupytext --to py feature_distance.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
