{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "direct-authorization",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@author: Eric Tsai <eric492718@gmail.com>\\n@brief: first and last ngram features\\n@note: in the final submission, we only used intersect count, NOT including intersect position.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "@author: Eric Tsai <eric492718@gmail.com>\n",
    "@brief: first and last ngram features\n",
    "@note: in the final submission, we only used intersect count, NOT including intersect position.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-clothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import config\n",
    "from utils import dist_utils, ngram_utils, nlp_utils, np_utils, pkl_utils\n",
    "from utils import logging_utils, time_utils\n",
    "from feature_base import BaseEstimator, PairwiseFeatureWrapper\n",
    "from feature_intersect_position import _inter_pos_list, _inter_norm_pos_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "revised-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune the token pattern to get a better correlation with y_train\n",
    "# token_pattern = r\"(?u)\\b\\w\\w+\\b\"\n",
    "# token_pattern = r\"\\w{1,}\"\n",
    "# token_pattern = r\"\\w+\"\n",
    "# token_pattern = r\"[\\w']+\"\n",
    "token_pattern = \" \" # just split the text into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "about-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- Count ----------------------------------\n",
    "class Count_Ngram_BaseEstimator(BaseEstimator):\n",
    "    \"\"\"\n",
    "    using edit distance to decide two string whether match\n",
    "    \"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, idx, aggregation_mode=\"\", \n",
    "        str_match_threshold=config.STR_MATCH_THRESHOLD):\n",
    "        super().__init__(obs_corpus, target_corpus, aggregation_mode)\n",
    "        self.idx = idx\n",
    "        self.ngram = ngram\n",
    "        self.ngram_str = ngram_utils._ngram_str_map[self.ngram]\n",
    "        self.str_match_threshold = str_match_threshold\n",
    "\n",
    "    def _get_match_count(self, obs, target, idx):\n",
    "        cnt = 0\n",
    "        if (len(obs) != 0) and (len(target) != 0):\n",
    "            for word in target:\n",
    "                if dist_utils._is_str_match(word, obs[idx], self.str_match_threshold):\n",
    "                    cnt += 1\n",
    "        return cnt\n",
    "\n",
    "    def transform_one(self, obs, target, id):\n",
    "        obs_tokens = nlp_utils._tokenize(obs, token_pattern)\n",
    "        target_tokens = nlp_utils._tokenize(target, token_pattern)\n",
    "        obs_ngrams = ngram_utils._ngrams(obs_tokens, self.ngram)\n",
    "        target_ngrams = ngram_utils._ngrams(target_tokens, self.ngram)\n",
    "        return self._get_match_count(obs_ngrams, target_ngrams, self.idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bright-arrest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstIntersectCount_Ngram(Count_Ngram_BaseEstimator):\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\", \n",
    "        str_match_threshold=config.STR_MATCH_THRESHOLD):\n",
    "        super().__init__(obs_corpus, target_corpus, ngram, 0, aggregation_mode, str_match_threshold)\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"FirstIntersectCount_%s\"%self.ngram_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "isolated-steel",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastIntersectCount_Ngram(Count_Ngram_BaseEstimator):\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\", \n",
    "        str_match_threshold=config.STR_MATCH_THRESHOLD):\n",
    "        super().__init__(obs_corpus, target_corpus, ngram, -1, aggregation_mode, str_match_threshold)\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"LastIntersectCount_%s\"%self.ngram_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "genuine-sport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Ratio -------------------------------------------\n",
    "class Ratio_Ngram_BaseEstimator(Count_Ngram_BaseEstimator):\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, idx, aggregation_mode=\"\", \n",
    "        str_match_threshold=config.STR_MATCH_THRESHOLD):\n",
    "        super().__init__(obs_corpus, target_corpus, ngram, idx, aggregation_mode, str_match_threshold)\n",
    "    def transform_one(self, obs, target, id):\n",
    "        obs_tokens = nlp_utils._tokenize(obs, token_pattern)\n",
    "        target_tokens = nlp_utils._tokenize(target, token_pattern)\n",
    "        obs_ngrams = ngram_utils._ngrams(obs_tokens, self.ngram)\n",
    "        target_ngrams = ngram_utils._ngrams(target_tokens, self.ngram)\n",
    "        return np_utils._try_divide(self._get_match_count(obs_ngrams, target_ngrams, self.idx), len(target_ngrams))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "royal-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstIntersectRatio_Ngram(Ratio_Ngram_BaseEstimator):\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\", \n",
    "        str_match_threshold=config.STR_MATCH_THRESHOLD):\n",
    "        super().__init__(obs_corpus, target_corpus, ngram, 0, aggregation_mode, str_match_threshold)\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"FirstIntersectRatio_%s\"%self.ngram_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "upset-evolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastIntersectRatio_Ngram(Ratio_Ngram_BaseEstimator):\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\", \n",
    "        str_match_threshold=config.STR_MATCH_THRESHOLD):\n",
    "        super().__init__(obs_corpus, target_corpus, ngram, -1, aggregation_mode, str_match_threshold)\n",
    "        \n",
    "    def __name__(self):\n",
    "        return \"LastIntersectRatio_%s\"%self.ngram_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "linear-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------- Position ---------------------\n",
    "class Position_Ngram_BaseEstimator(BaseEstimator):\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, idx, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, aggregation_mode)\n",
    "        self.idx = idx\n",
    "        self.ngram = ngram\n",
    "        self.ngram_str = ngram_utils._ngram_str_map[self.ngram]\n",
    "    def transform_one(self, obs, target, id):\n",
    "        obs_tokens = nlp_utils._tokenize(obs, token_pattern)\n",
    "        target_tokens = nlp_utils._tokenize(target, token_pattern)\n",
    "        obs_ngrams = ngram_utils._ngrams(obs_tokens, self.ngram)\n",
    "        target_ngrams = ngram_utils._ngrams(target_tokens, self.ngram)\n",
    "        return _inter_pos_list(target_ngrams, [obs_ngrams[self.idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accessory-tackle",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstIntersectPosition_Ngram(Position_Ngram_BaseEstimator):\n",
    "    \"\"\"Single aggregation features\"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, ngram, 0, aggregation_mode)\n",
    "        \n",
    "    def __name__(self):\n",
    "        if isinstance(self.aggregation_mode, str):\n",
    "            feat_name = \"FirstIntersectPosition_%s_%s\"%(\n",
    "                self.ngram_str, string.capwords(self.aggregation_mode))\n",
    "        elif isinstance(self.aggregation_mode, list):\n",
    "            feat_name = [\"FirstIntersectPosition_%s_%s\"%(\n",
    "                self.ngram_str, string.capwords(m)) for m in self.aggregation_mode]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "iraqi-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastIntersectPosition_Ngram(Position_Ngram_BaseEstimator):\n",
    "    \"\"\"Single aggregation features\"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, ngram, -1, aggregation_mode)\n",
    "        \n",
    "    def __name__(self):\n",
    "        if isinstance(self.aggregation_mode, str):\n",
    "            feat_name = \"LastIntersectPosition_%s_%s\"%(\n",
    "                self.ngram_str, string.capwords(self.aggregation_mode))\n",
    "        elif isinstance(self.aggregation_mode, list):\n",
    "            feat_name = [\"LastIntersectPosition_%s_%s\"%(\n",
    "                self.ngram_str, string.capwords(m)) for m in self.aggregation_mode]\n",
    "        return feat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quiet-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------- Norm Position ----------------------------------\n",
    "class NormPosition_Ngram_BaseEstimator(BaseEstimator):\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, idx, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, aggregation_mode)\n",
    "        self.idx = idx\n",
    "        self.ngram = ngram\n",
    "        self.ngram_str = ngram_utils._ngram_str_map[self.ngram]\n",
    "    def transform_one(self, obs, target, id):\n",
    "        obs_tokens = nlp_utils._tokenize(obs, token_pattern)\n",
    "        target_tokens = nlp_utils._tokenize(target, token_pattern)\n",
    "        obs_ngrams = ngram_utils._ngrams(obs_tokens, self.ngram)\n",
    "        target_ngrams = ngram_utils._ngrams(target_tokens, self.ngram)\n",
    "        return _inter_norm_pos_list(target_ngrams, [obs_ngrams[self.idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "intellectual-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirstIntersectNormPosition_Ngram(NormPosition_Ngram_BaseEstimator):\n",
    "    \"\"\"Single aggregation features\"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, ngram, 0, aggregation_mode)\n",
    "        \n",
    "    def __name__(self):\n",
    "        if isinstance(self.aggregation_mode, str):\n",
    "            feat_name = \"FirstIntersectNormPosition_%s_%s\"%(\n",
    "                self.ngram_str, string.capwords(self.aggregation_mode))\n",
    "        elif isinstance(self.aggregation_mode, list):\n",
    "            feat_name = [\"FirstIntersectNormPosition_%s_%s\"%(\n",
    "                self.ngram_str, string.capwords(m)) for m in self.aggregation_mode]\n",
    "        return feat_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "armed-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LastIntersectNormPosition_Ngram(NormPosition_Ngram_BaseEstimator):\n",
    "    \"\"\"Single aggregation features\"\"\"\n",
    "    def __init__(self, obs_corpus, target_corpus, ngram, aggregation_mode=\"\"):\n",
    "        super().__init__(obs_corpus, target_corpus, ngram, -1, aggregation_mode)\n",
    "        \n",
    "    def __name__(self):\n",
    "        if isinstance(self.aggregation_mode, str):\n",
    "            feat_name = \"LastIntersectNormPosition_%s_%s\"%(\n",
    "                self.ngram_str, string.capwords(self.aggregation_mode))\n",
    "        elif isinstance(self.aggregation_mode, list):\n",
    "            feat_name = [\"LastIntersectNormPosition_%s_%s\"%(\n",
    "                self.ngram_str, string.capwords(m)) for m in self.aggregation_mode]\n",
    "        return feat_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lightweight-buddy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------- Main --------------------------------------\n",
    "def run_count():\n",
    "    logname = \"generate_feature_first_last_ngram_count_%s.log\"%time_utils._timestamp()\n",
    "    logger = logging_utils._get_logger(config.LOG_DIR, logname)\n",
    "    dfAll = pkl_utils._load(config.ALL_DATA_LEMMATIZED_STEMMED)\n",
    "\n",
    "    generators = [\n",
    "        FirstIntersectCount_Ngram, \n",
    "        LastIntersectCount_Ngram, \n",
    "        FirstIntersectRatio_Ngram, \n",
    "        LastIntersectRatio_Ngram, \n",
    "    ]\n",
    "\n",
    "    obs_fields_list = []\n",
    "    target_fields_list = []\n",
    "    ## query in document\n",
    "    obs_fields_list.append( [\"search_term\", \"search_term_product_name\", \"search_term_alt\", \"search_term_auto_corrected\"][:2] )\n",
    "    target_fields_list.append( [\"product_title\", \"product_title_product_name\", \"product_description\", \"product_attribute\", \"product_brand\", \"product_color\"] )\n",
    "    ## document in query\n",
    "    obs_fields_list.append( [\"product_title\", \"product_title_product_name\", \"product_description\", \"product_attribute\", \"product_brand\", \"product_color\"] )\n",
    "    target_fields_list.append( [\"search_term\", \"search_term_product_name\", \"search_term_alt\", \"search_term_auto_corrected\"][:2] )\n",
    "    ngrams = [1,2,3,12,123][:3]\n",
    "    for obs_fields, target_fields in zip(obs_fields_list, target_fields_list):\n",
    "        for generator in generators:\n",
    "            for ngram in ngrams:\n",
    "                param_list = [ngram]\n",
    "                pf = PairwiseFeatureWrapper(generator, dfAll, obs_fields, target_fields, param_list, config.FEAT_DIR, logger)\n",
    "                pf.go()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "intellectual-mortality",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_position():\n",
    "    logname = \"generate_feature_first_last_ngram_position_%s.log\"%time_utils._timestamp()\n",
    "    logger = logging_utils._get_logger(config.LOG_DIR, logname)\n",
    "    dfAll = pkl_utils._load(config.ALL_DATA_LEMMATIZED_STEMMED)\n",
    "\n",
    "    generators = [\n",
    "        FirstIntersectPosition_Ngram, \n",
    "        LastIntersectPosition_Ngram, \n",
    "        FirstIntersectNormPosition_Ngram, \n",
    "        LastIntersectNormPosition_Ngram, \n",
    "    ]\n",
    "\n",
    "    obs_fields_list = []\n",
    "    target_fields_list = []\n",
    "    ## query in document\n",
    "    obs_fields_list.append( [\"search_term\", \"search_term_product_name\", \"search_term_alt\", \"search_term_auto_corrected\"][:2] )\n",
    "    target_fields_list.append( [\"product_title\", \"product_title_product_name\", \"product_description\", \"product_attribute\", \"product_brand\", \"product_color\"] )\n",
    "    ## document in query\n",
    "    obs_fields_list.append( [\"product_title\", \"product_title_product_name\", \"product_description\", \"product_attribute\", \"product_brand\", \"product_color\"] )\n",
    "    target_fields_list.append( [\"search_term\", \"search_term_product_name\", \"search_term_alt\", \"search_term_auto_corrected\"][:2] )\n",
    "    ngrams = [1,2,3,12,123][:3]\n",
    "    aggregation_mode = [\"mean\", \"std\", \"max\", \"min\", \"median\"]\n",
    "    for obs_fields, target_fields in zip(obs_fields_list, target_fields_list):\n",
    "        for generator in generators:\n",
    "            for ngram in ngrams:\n",
    "                param_list = [ngram, aggregation_mode]\n",
    "                pf = PairwiseFeatureWrapper(generator, dfAll, obs_fields, target_fields, param_list, config.FEAT_DIR, logger)\n",
    "                pf.go()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "classified-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    run_count()\n",
    "    # # not used in final submission\n",
    "    # run_position()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "loved-security",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jupytext] Reading feature_first_last_ngram.ipynb in format ipynb\n",
      "[jupytext] Writing feature_first_last_ngram.py (destination file replaced)\n"
     ]
    }
   ],
   "source": [
    "# convert notebook.ipynb to a .py file\n",
    "!jupytext --to py feature_first_last_ngram.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-blowing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
